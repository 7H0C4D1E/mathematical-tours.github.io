\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Machine Learning}{201}{chapter.14}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Unsupervised Learning}{201}{section.14.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.1.1}Dimensionality Reduction and PCA}{201}{subsection.14.1.1}\protected@file@percent }
\newlabel{eq-emp-cov}{{14.1}{201}{Dimensionality Reduction and PCA}{equation.14.1.1}{}}
\newlabel{eq-cov-approx}{{14.2}{201}{Dimensionality Reduction and PCA}{equation.14.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.1}{\ignorespaces  Empirical covariance of the data and its associated singular values. }}{202}{figure.14.1}\protected@file@percent }
\newlabel{fig-cov}{{14.1}{202}{Empirical covariance of the data and its associated singular values}{figure.14.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.2}{\ignorespaces PCA main axes capture variance}}{202}{figure.14.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.3}{\ignorespaces  2-D and 3-D PCA vizualization of the input clouds. }}{203}{figure.14.3}\protected@file@percent }
\newlabel{fig-pca}{{14.3}{203}{2-D and 3-D PCA vizualization of the input clouds}{figure.14.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.1.2}Clustering and $k$-means}{203}{subsection.14.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{$k$-means}{203}{section*.126}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.4}{\ignorespaces $k$-means clusters according to Vornoi cells.}}{203}{figure.14.4}\protected@file@percent }
\newlabel{eq-kmeans-1}{{14.3}{203}{$k$-means}{equation.14.1.3}{}}
\newlabel{eq-kmeans-2}{{14.4}{203}{$k$-means}{equation.14.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.5}{\ignorespaces  Left: iteration of $k$-means algorithm. Right: histogram of points belonging to each class after the $k$-means optimization. }}{204}{figure.14.5}\protected@file@percent }
\newlabel{fig-kmeans}{{14.5}{204}{Left: iteration of $k$-means algorithm. Right: histogram of points belonging to each class after the $k$-means optimization}{figure.14.5}{}}
\@writefile{toc}{\contentsline {paragraph}{$k$-means++}{204}{section*.127}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Lloyd algorithm and continuous densities.}{204}{section*.128}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.6}{\ignorespaces  Iteration of $k$-means algorithm (Lloyd algorithm) on continuous densities $\mu $. Top: uniform. Bottom: non-uniform (the densities of $\mu $ with respect to the Lebesgue measure is displayed as a grayscale image in the background). }}{205}{figure.14.6}\protected@file@percent }
\newlabel{fig-lloyd}{{14.6}{205}{Iteration of $k$-means algorithm (Lloyd algorithm) on continuous densities $\mu $. Top: uniform. Bottom: non-uniform (the densities of $\mu $ with respect to the Lebesgue measure is displayed as a grayscale image in the background)}{figure.14.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.2}Empirical Risk Minimization}{205}{section.14.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.1}Empirical Risk}{205}{subsection.14.2.1}\protected@file@percent }
\newlabel{eq-erm-1}{{14.5}{205}{Empirical Risk}{equation.14.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.2}Prediction and Consistency}{205}{subsection.14.2.2}\protected@file@percent }
\newlabel{eq-consistency-estim}{{14.6}{205}{Prediction and Consistency}{equation.14.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.3}Parametric Approaches and Regularization}{206}{subsection.14.2.3}\protected@file@percent }
\newlabel{eq-erm-param}{{14.7}{206}{Parametric Approaches and Regularization}{equation.14.2.7}{}}
\newlabel{eq-consistency-param}{{14.8}{206}{Parametric Approaches and Regularization}{equation.14.2.8}{}}
\@writefile{toc}{\contentsline {paragraph}{Prediction vs. estimation risks.}{206}{section*.129}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.4}Testing Set and Cross-validation}{206}{subsection.14.2.4}\protected@file@percent }
\newlabel{eq-valid-risk}{{14.9}{206}{Testing Set and Cross-validation}{equation.14.2.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.8}{\ignorespaces  Conditional expectation. }}{207}{figure.14.8}\protected@file@percent }
\newlabel{fig-bound-regul}{{14.8}{207}{Conditional expectation}{figure.14.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.3}Supervised Learning: Regression}{207}{section.14.3}\protected@file@percent }
\newlabel{sec-regression}{{14.3}{207}{Supervised Learning: Regression}{section.14.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.7}{\ignorespaces Probabilistic modelling.}}{207}{figure.14.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.1}Linear Regression}{207}{subsection.14.3.1}\protected@file@percent }
\newlabel{sec-linear-models}{{14.3.1}{207}{Linear Regression}{subsection.14.3.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Least square and conditional expectation.}{207}{section*.130}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.9}{\ignorespaces Linear regression.}}{208}{figure.14.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Penalized linear models.}{208}{figure.14.9}\protected@file@percent }
\newlabel{eq-erm-lin}{{14.10}{208}{Penalized linear models}{equation.14.3.10}{}}
\newlabel{eq-empirical-conver}{{14.11}{208}{Penalized linear models}{equation.14.3.11}{}}
\@writefile{toc}{\contentsline {paragraph}{Ridge regression (quadratic penalization).}{209}{section*.132}\protected@file@percent }
\newlabel{eq-linest-std}{{14.12}{209}{Ridge regression (quadratic penalization)}{equation.14.3.12}{}}
\newlabel{eq-linest-woodbury}{{14.13}{209}{Ridge regression (quadratic penalization)}{equation.14.3.13}{}}
\newlabel{eq-sc-stat}{{14.14}{209}{}{equation.14.3.14}{}}
\newlabel{eq-rate-estim}{{14.15}{209}{}{equation.14.3.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.4}Supervised Learning: Classification}{209}{section.14.4}\protected@file@percent }
\newlabel{sec-classif}{{14.4}{209}{Supervised Learning: Classification}{section.14.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.4.1}Nearest Neighbors Classification}{209}{subsection.14.4.1}\protected@file@percent }
\newlabel{sec-nn-classif}{{14.4.1}{209}{Nearest Neighbors Classification}{subsection.14.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.10}{\ignorespaces Nearest neighbors.}}{209}{figure.14.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.11}{\ignorespaces  $k$-nearest-neighbor classification boundary function. }}{210}{figure.14.11}\protected@file@percent }
\newlabel{fig-hist-classif}{{14.11}{210}{$k$-nearest-neighbor classification boundary function}{figure.14.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.4.2}Two Classes Logistic Classification}{210}{subsection.14.4.2}\protected@file@percent }
\newlabel{sec-two-class-logit}{{14.4.2}{210}{Two Classes Logistic Classification}{subsection.14.4.2}{}}
\newlabel{eq-two-class-logit-model}{{14.16}{210}{Two Classes Logistic Classification}{equation.14.4.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.12}{\ignorespaces  1-D and 2-D logistic classification, showing the impact of $|\tmspace  -\thinmuskip {.1667em}| \beta  |\tmspace  -\thinmuskip {.1667em}|$ on the sharpness of the classification boundary. }}{211}{figure.14.12}\protected@file@percent }
\newlabel{fig-losses}{{14.12}{211}{1-D and 2-D logistic classification, showing the impact of $\norm {\be }$ on the sharpness of the classification boundary}{figure.14.12}{}}
\newlabel{eq-logistic-optim}{{14.17}{211}{Two Classes Logistic Classification}{equation.14.4.17}{}}
\newlabel{eq-logistic-loss}{{14.18}{211}{Two Classes Logistic Classification}{equation.14.4.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.13}{\ignorespaces  Comparison of loss functions. }}{212}{figure.14.13}\protected@file@percent }
\newlabel{fig-losses}{{14.13}{212}{Comparison of loss functions}{figure.14.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.14}{\ignorespaces  Influence on the separation distance between the class on the classification probability. }}{212}{figure.14.14}\protected@file@percent }
\newlabel{fig-separation-influ}{{14.14}{212}{Influence on the separation distance between the class on the classification probability}{figure.14.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.4.3}Multi-Classes Logistic Classification}{212}{subsection.14.4.3}\protected@file@percent }
\newlabel{sec-multiclass-logit}{{14.4.3}{212}{Multi-Classes Logistic Classification}{subsection.14.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.15}{\ignorespaces  2-D and 3-D PCA vizualization of the digits images. }}{213}{figure.14.15}\protected@file@percent }
\newlabel{fig-digits}{{14.15}{213}{2-D and 3-D PCA vizualization of the digits images}{figure.14.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.16}{\ignorespaces  Results of digit classification Left: probability $h(x)_\ell $ of belonging to each of the 9 first classes (displayed over a 2-D PCA space). Right: colors reflect probability $h(x)$ of belonging to classes. }}{214}{figure.14.16}\protected@file@percent }
\newlabel{fig-digits-classes}{{14.16}{214}{Results of digit classification Left: probability $h(x)_\ell $ of belonging to each of the 9 first classes (displayed over a 2-D PCA space). Right: colors reflect probability $h(x)$ of belonging to classes}{figure.14.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.5}Kernel Methods}{214}{section.14.5}\protected@file@percent }
\newlabel{sec-kernel-methods}{{14.5}{214}{Kernel Methods}{section.14.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.5.1}Reproducing Kernel Hilbert Space}{214}{subsection.14.5.1}\protected@file@percent }
\newlabel{eq-kernel-generic}{{14.19}{215}{}{equation.14.5.19}{}}
\newlabel{eq-rkhs-representer}{{14.20}{215}{}{equation.14.5.20}{}}
\newlabel{eq-rkhs-variational}{{14.21}{215}{}{equation.14.5.21}{}}
\newlabel{eq-kernel-interp}{{14.22}{215}{Reproducing Kernel Hilbert Space}{equation.14.5.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.17}{\ignorespaces  Regression using a Gaussian kernel. }}{216}{figure.14.17}\protected@file@percent }
\newlabel{fig-kernel}{{14.17}{216}{Regression using a Gaussian kernel}{figure.14.17}{}}
\newlabel{eq-gauss-kernel}{{14.23}{216}{Reproducing Kernel Hilbert Space}{equation.14.5.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.5.2}Examples of Kernelized Algorithms}{216}{subsection.14.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Kernelized ridge regression.}{216}{section*.133}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Kernelized logistic classification.}{216}{section*.134}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14.18}{\ignorespaces  Non-linear classification using a Gaussian kernel. }}{217}{figure.14.18}\protected@file@percent }
\newlabel{fig-classes-kernel}{{14.18}{217}{Non-linear classification using a Gaussian kernel}{figure.14.18}{}}
\@writefile{toc}{\contentsline {paragraph}{Kernelized nearest-neihbors. }{217}{section*.135}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Kernel on strings. }{217}{section*.136}\protected@file@percent }
\@setckpt{chapters/machine-learning}{
\setcounter{page}{218}
\setcounter{equation}{23}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{1}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{14}
\setcounter{section}{5}
\setcounter{subsection}{2}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{18}
\setcounter{table}{0}
\setcounter{Item}{3}
\setcounter{Hfootnote}{3}
\setcounter{bookmark@seq@number}{215}
\setcounter{parentequation}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{thm}{30}
\setcounter{prop}{55}
\setcounter{defn}{1}
\setcounter{cor}{0}
\setcounter{alg}{0}
\setcounter{lem}{6}
\setcounter{rem}{3}
\setcounter{exmp}{3}
\setcounter{float@type}{32}
\setcounter{listing}{0}
\setcounter{lstnumber}{1}
\setcounter{mdf@globalstyle@cnt}{0}
\setcounter{mdfcountframes}{0}
\setcounter{mdf@env@i}{0}
\setcounter{mdf@env@ii}{0}
\setcounter{mdf@zref@counter}{0}
\setcounter{section@level}{4}
\setcounter{lstlisting}{0}
}
